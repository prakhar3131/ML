{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.What is a parameter?\n",
        "  An internal variable of a model whose value is learned from data during model training.\n",
        "2.What is correlation?\n",
        "  Correlation determines the relationship between two variable , whether they are positively correlated or negatively corelated.\n",
        "  In negative correlation if one variable increases in value then at the same time value of other variable will decrease.\n",
        "3.Define Machine Learning. What are the main components in Machine Learning?\n",
        "  Machine Learning refers to analyzing the patterns and stastistical models so that computer can perform tasks without being explicitely pogrammed.\n",
        "  Main componenst are:- DATA,MODELS,EVALUATION,TRAINING\n",
        "4.How does loss value help in determining whether the model is good or not?\n",
        "  Loss value is the difference between the model's predicted value and actual value.If the difference is large then mode is not good and vice-versa.\n",
        "5.What are continuous and categorical variables?\n",
        "  Continous data refers refers to all quatitative features in model whereas categorical data refers o all qualitative features.\n",
        "6.How do we handle categorical variables in Machine Learning? What are the\n",
        "  common techniques?\n",
        "  In ML categorical data is handled by converting it into numerical data through a process called Data encoding.Various techniques are:-\n",
        "  -ONE HOT ENCODING\n",
        "  -ORDINAL ENCODNG\n",
        "  -TARGET GUIDED ENCODING\n",
        "7.What do you mean by training and testing a dataset?\n",
        "  Training and Testing are two phases of model training.In training phase model is fed with training dataset through which it analyzes patterns and learns to mae predictions whereas in testing phase models is fed with completely new dataset to test the model's accuracy.\n",
        "8.What is sklearn.preprocessing?\n",
        "  sklearn.preprocessing is a module in library scikit-learn that provides tools for preprocessing of raw data in ML.\n",
        "9.What is a Test set?\n",
        "  Dataset used to test the model's accuracy is called test set.\n",
        "10.How do we split data for model fitting (training and testing) in Python?\n",
        "   In python for machine learning one can split data into training and test data using train_test_split from model selection module in scikit library.\n",
        "\n",
        "11.Why do we have to perform EDA before fitting a model to the data?\n",
        "   We perform exploratory data analysis before fitting a model to the data so that we can draw valuable insights from the data depeding upon our target variable before training the data.\n",
        "15.What is causation? Explain difference between correlation and causation   with an example.\n",
        "   Causation is a cause-and-effect relationship where one event directly brings about another event, while correlation is a statistical association where two variables change in relation to each other but one does not necessarily cause the other\n",
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "   \n",
        "   An optimizer is an algorithm used in machine learning and deep learning to adjust the parameters (weights and biases) of a model during training, with the goal of minimizing a specified loss function.\n",
        "17.What is sklearn.linear_model ?\n",
        "  sklearn.linear_model is a module within the scikit-learn (sklearn) Python library that provides a collection of algorithms for building linear model\n",
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        "  Feature Scaling refers to bringing all the features of dataset at the same scale before training the model.It helps by decreasing the computational cost and coplexity of the model.\n",
        "25.Explain data encoding?\n",
        "   Data Encoding is the process of converting categorical data into numerical data.\n",
        "14.How can you find correlation between variables in Python?\n",
        "   We can find correlation between variables in python using pearson correlation formula uisng numpy library or through visualization using pandas library.\n",
        "18.What does model.fit() do?\n",
        "   Model.fit() in machine learning ib python is used gto fit training data in train the model. Arguments given are of x and y from training data\n",
        "19.What does model.predict() do?\n",
        "   model.predict() in machine learning using python is used to predict the target values after training the model. Argumets given is the value of independent variable x.\n",
        "20.What are continuous and categorical variables?\n",
        "  Continous data is kind of quantitavive or numerical data and categorical data is kind of grouped or qualitative data.\n",
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        "   Feture Scaling refers to the process of bringing all the correlated features in dataset on to the same scale for comparing purposes.It helps in mahcine learning by decreasing the computational cost for model training also decreases the the computational time by decreasing the compplexity of the model.\n",
        "23.What is sklearn.preprocessing?\n",
        "   It is used for pre processing of dataset before starting to train he model.\n",
        "25.Explain data encoding?\n",
        "  Label Encoding is a data preprocessing technique in Machine Learning used to convert categorical values into numerical labels."
      ],
      "metadata": {
        "id": "xR7kgt8SYhst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U_D0FluikM8d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W766o9l1X_-F",
        "outputId": "bd9b35ef-4c77-4d13-8662-5901d83bf00b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.         -0.72772837]\n",
            " [-0.72772837  1.        ]]\n"
          ]
        }
      ],
      "source": [
        "#12.How can you find correlation between variables in Python?\n",
        "\n",
        "import numpy as np\n",
        "a=[1,2,3,4,5]\n",
        "b=[3836,4753,936]\n",
        "c=np.corrcoef(a,b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22.How do we perform scaling in Python?\n",
        "#scaling in python can be done by three methods-STANDARDIZATION,NORMALIZATION,UNIT VECTOR\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "A=np.array([56,87,6,78,54])\n",
        "\n",
        "B=np.mean(A)\n",
        "C=np.std(A)\n",
        "\n",
        "#zscore\n",
        "for i in A:\n",
        "  D=print((i-B)/C)\n",
        "\n",
        "np.array(D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0kBEGaBrILD",
        "outputId": "8acbaa94-0826-498d-d633-d36346219f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.007116761778869751\n",
            "1.095981313945926\n",
            "-1.7863072064962822\n",
            "0.7757270338967917\n",
            "-0.07828437956756625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(None, dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oe4lAddv87Bc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}